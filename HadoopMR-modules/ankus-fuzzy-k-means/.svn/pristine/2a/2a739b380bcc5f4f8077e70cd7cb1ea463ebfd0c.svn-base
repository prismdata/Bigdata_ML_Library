package org.ankus.mapreduce.algorithms.clustering.FuzzyCMeans;

import java.io.IOException;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Reducer.Context;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class Reducer_Random_Reducer extends Reducer<Text, Text, Text, Text> {
	private Logger logger = LoggerFactory.getLogger(Reducer_Random_Reducer.class);
	
	@Override
	protected void setup(Context context) throws IOException, InterruptedException
	{
		logger.info("setup");
	}
	
	protected void reduce(Text Attribute, Iterable<Text> Weights, Context context) throws IOException, InterruptedException
	{
		String vectors = "";
		
		for (Text Weight : Weights) 
		{
			String WeightStr = Weight.toString();
			//user vector's feacture delimiter is dependenty by user
			//and emit function is distinguish key value using tab
			//so To identify Weight Value, We use unicode \u00001
			context.write(new Text(Attribute), new Text("\u0001" + WeightStr));
		}
		
		
	}
}
