수치 데이터에 대해 확률 가중치를 기반으로 소속 확률이 높은 것끼리 묶는 군집 알고리즘입니다.

수행방법:
hadoop jar ankus-core2-fuzzy-k-means-1.1.0.jar FuzzyKMeans \
-input [입력 파일 또는 입력 폴더] \
-output [출력 데이터 폴더 경로] \
-indexList [읽을 데이터의 컬럼 인덱스 리스트] \
-delimer [컬럼란 구분자] \
-k [클러스터 수<0 이상의 양의 정수>] \
-p [클러스터 가중치<0에서1사이의 실수>] \
-maxIteration [군집 할당 반복수<1이상의 양의 실수>]

수행 예제:
hadoop jar ankus-core2-fuzzy-k-means-1.1.0.jar \
FuzzyKMeans \
-input /data/kmeans.csv \
-output /result/fuzzy-kmeans_csv -delimiter , \
-indexList 0,1,2,3 \
-k 3 \
-p 0.1 \
-maxIteration 10

*입력 예제
........
5.1,2.5,3,1.1,versicolor
5.7,2.8,4.1,1.3,versicolor
6.3,3.3,6,2.5,virginica
5.8,2.7,5.1,1.9,virginica
7.1,3,5.9,2.1,virginica
6.3,2.9,5.6,1.8,virginica
6.5,3,5.8,2.2,virginica
7.6,3,6.6,2.1,virginica
4.9,2.5,4.5,1.7,virginica
7.3,2.9,6.3,1.8,virginica
6.7,2.5,5.8,1.8,virginica
7.2,3.6,6.1,2.5,virginica
6.5,3.2,5.1,2,virginica
6.4,2.7,5.3,1.9,virginica
6.8,3,5.5,2.1,virginica
.........
*출력 예제
**/result/fuzzy-kmeans_csv/finalResult/part-m-00000 클러스터 할당 결과
[변수1, 변수2, 변수3, 변수4, 군집번호]
.....
5,3.2,1.2,0.2,0
5.5,3.5,1.3,0.2,0
4.9,3.1,1.5,0.1,0
4.4,3,1.3,0.2,0
5.1,3.4,1.5,0.2,0
5,3.5,1.3,0.3,0
4.5,2.3,1.3,0.3,0
4.4,3.2,1.3,0.2,0
5,3.5,1.6,0.6,0
5.1,3.8,1.9,0.4,0
4.8,3,1.4,0.3,0
5.1,3.8,1.6,0.2,0
4.6,3.2,1.4,0.2,0
5.3,3.7,1.5,0.2,0
5,3.3,1.4,0.2,0
7,3.2,4.7,1.4,2
6.4,3.2,4.5,1.5,1
6.9,3.1,4.9,1.5,2
5.5,2.3,4,1.3,1
6.5,2.8,4.6,1.5,1
5.7,2.8,4.5,1.3,1
6.3,3.3,4.7,1.6,1
4.9,2.4,3.3,1,1
6.6,2.9,4.6,1.3,1
5.2,2.7,3.9,1.4,1
5,2,3.5,1,1
....
**/result/fuzzy-kmeans_csv/Centroid/part-r-00000 : 각 속성별 클러스터 소속 비율
[군집번호, 변수번호, 가중치]
0	0,5.0035
0	1,3.4037
0	2,1.4839
0	3,0.2511
1	0,5.8755
1	1,2.7564
1	2,4.3441
1	3,1.387
2	0,6.7585
2	1,3.0474
2	2,5.626
2	3,2.0454