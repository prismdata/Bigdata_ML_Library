package org.ankus.mapreduce.algorithms.association.pfpgrowth;

import java.io.IOException;
import java.util.Iterator;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Reducer.Context;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class PfpgrowthSupportCounterCombiner  extends Reducer <Text,IntWritable, Text, IntWritable >
{
	private IntWritable result = new IntWritable();
	private Logger logger = LoggerFactory.getLogger(PfpgrowthSupportCountReducer.class);
	
	double tc=0;
	double support=0;
	double minSup=0;
	
	
	public void reduce(Text key, Iterable<IntWritable> values, Context context)
		throws IOException, InterruptedException{
		int sum =0;
		
		for(IntWritable val: values)
		{
			logger.info("CumtomCombiner : key" + key.toString() + " VALUE " + val.get());
			sum += val.get();
		}
		result.set(sum);		
		context.write(key, result);
	
	}
}
