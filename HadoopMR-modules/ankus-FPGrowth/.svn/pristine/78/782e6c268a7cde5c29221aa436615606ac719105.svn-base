package org.ankus.mapreduce.algorithms.association.pfpgrowth;

import java.io.IOException;

import org.ankus.util.ArgumentsConstants;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Reducer.Context;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class PfpgrowthSupportCountReducer  extends Reducer <Text,IntWritable, Text, IntWritable >
{
	private IntWritable result = new IntWritable();
	private Logger logger = LoggerFactory.getLogger(PfpgrowthSupportCountReducer.class);
	
	double tc=0;
	double support=0;
	double minSup=0;
	
	@Override
	public void setup(Context context) throws IOException, InterruptedException
	{

	}
	public void reduce(Text key, Iterable<IntWritable> values, Context context)
		throws IOException, InterruptedException{
		int sum =0;
		
		for(IntWritable val: values)
		{
			logger.info(">key" + key.toString() + " VALUE " + val.get());
			sum += val.get();
		}
		result.set(sum);		
		context.write(key, result);

	}
}
